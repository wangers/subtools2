<!doctype html>
<html class="no-js" lang="en" data-content_root="">
  <head><meta charset="utf-8"/>
    <meta name="viewport" content="width=device-width,initial-scale=1"/>
    <meta name="color-scheme" content="light dark"><meta name="viewport" content="width=device-width, initial-scale=1" />
<link rel="index" title="Index" href="../../genindex.html" /><link rel="search" title="Search" href="../../search.html" /><link rel="next" title="egrecho.utils.apply" href="../utils/index.html" /><link rel="prev" title="egrecho.core.teacher" href="teacher.html" />

    <!-- Generated with Sphinx 7.1.2 and Furo 2024.05.06 -->
        <title>egrecho.core.tokenizer - Documentation</title>
      <link rel="stylesheet" type="text/css" href="../../_static/pygments.css?v=649a27d8" />
    <link rel="stylesheet" type="text/css" href="../../_static/styles/furo.css?v=387cc868" />
    <link rel="stylesheet" type="text/css" href="../../_static/copybutton.css?v=76b2166b" />
    <link rel="stylesheet" type="text/css" href="../../_static/tabs.css?v=4c969af8" />
    <link rel="stylesheet" type="text/css" href="../../_static/togglebutton.css?v=13237357" />
    <link rel="stylesheet" type="text/css" href="../../_static/styles/furo-extensions.css?v=36a5483c" />
    <link rel="stylesheet" type="text/css" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.0.0/css/fontawesome.min.css" />
    <link rel="stylesheet" type="text/css" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.0.0/css/solid.min.css" />
    <link rel="stylesheet" type="text/css" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.0.0/css/brands.min.css" />
    
    


<style>
  body {
    --color-code-background: #f0f0f0;
  --color-code-foreground: black;
  
  }
  @media not print {
    body[data-theme="dark"] {
      --color-code-background: #202020;
  --color-code-foreground: #d0d0d0;
  
    }
    @media (prefers-color-scheme: dark) {
      body:not([data-theme="light"]) {
        --color-code-background: #202020;
  --color-code-foreground: #d0d0d0;
  
      }
    }
  }
</style></head>
  <body>
    
    <script>
      document.body.dataset.theme = localStorage.getItem("theme") || "auto";
    </script>
    

<svg xmlns="http://www.w3.org/2000/svg" style="display: none;">
  <symbol id="svg-toc" viewBox="0 0 24 24">
    <title>Contents</title>
    <svg stroke="currentColor" fill="currentColor" stroke-width="0" viewBox="0 0 1024 1024">
      <path d="M408 442h480c4.4 0 8-3.6 8-8v-56c0-4.4-3.6-8-8-8H408c-4.4 0-8 3.6-8 8v56c0 4.4 3.6 8 8 8zm-8 204c0 4.4 3.6 8 8 8h480c4.4 0 8-3.6 8-8v-56c0-4.4-3.6-8-8-8H408c-4.4 0-8 3.6-8 8v56zm504-486H120c-4.4 0-8 3.6-8 8v56c0 4.4 3.6 8 8 8h784c4.4 0 8-3.6 8-8v-56c0-4.4-3.6-8-8-8zm0 632H120c-4.4 0-8 3.6-8 8v56c0 4.4 3.6 8 8 8h784c4.4 0 8-3.6 8-8v-56c0-4.4-3.6-8-8-8zM115.4 518.9L271.7 642c5.8 4.6 14.4.5 14.4-6.9V388.9c0-7.4-8.5-11.5-14.4-6.9L115.4 505.1a8.74 8.74 0 0 0 0 13.8z"/>
    </svg>
  </symbol>
  <symbol id="svg-menu" viewBox="0 0 24 24">
    <title>Menu</title>
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor"
      stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather-menu">
      <line x1="3" y1="12" x2="21" y2="12"></line>
      <line x1="3" y1="6" x2="21" y2="6"></line>
      <line x1="3" y1="18" x2="21" y2="18"></line>
    </svg>
  </symbol>
  <symbol id="svg-arrow-right" viewBox="0 0 24 24">
    <title>Expand</title>
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor"
      stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather-chevron-right">
      <polyline points="9 18 15 12 9 6"></polyline>
    </svg>
  </symbol>
  <symbol id="svg-sun" viewBox="0 0 24 24">
    <title>Light mode</title>
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor"
      stroke-width="1" stroke-linecap="round" stroke-linejoin="round" class="feather-sun">
      <circle cx="12" cy="12" r="5"></circle>
      <line x1="12" y1="1" x2="12" y2="3"></line>
      <line x1="12" y1="21" x2="12" y2="23"></line>
      <line x1="4.22" y1="4.22" x2="5.64" y2="5.64"></line>
      <line x1="18.36" y1="18.36" x2="19.78" y2="19.78"></line>
      <line x1="1" y1="12" x2="3" y2="12"></line>
      <line x1="21" y1="12" x2="23" y2="12"></line>
      <line x1="4.22" y1="19.78" x2="5.64" y2="18.36"></line>
      <line x1="18.36" y1="5.64" x2="19.78" y2="4.22"></line>
    </svg>
  </symbol>
  <symbol id="svg-moon" viewBox="0 0 24 24">
    <title>Dark mode</title>
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor"
      stroke-width="1" stroke-linecap="round" stroke-linejoin="round" class="icon-tabler-moon">
      <path stroke="none" d="M0 0h24v24H0z" fill="none" />
      <path d="M12 3c.132 0 .263 0 .393 0a7.5 7.5 0 0 0 7.92 12.446a9 9 0 1 1 -8.313 -12.454z" />
    </svg>
  </symbol>
  <symbol id="svg-sun-half" viewBox="0 0 24 24">
    <title>Auto light/dark mode</title>
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor"
      stroke-width="1" stroke-linecap="round" stroke-linejoin="round" class="icon-tabler-shadow">
      <path stroke="none" d="M0 0h24v24H0z" fill="none"/>
      <circle cx="12" cy="12" r="9" />
      <path d="M13 12h5" />
      <path d="M13 15h4" />
      <path d="M13 18h1" />
      <path d="M13 9h4" />
      <path d="M13 6h1" />
    </svg>
  </symbol>
  <symbol id="svg-sun-with-moon" viewBox="0 0 24 24">
    <title>Auto light/dark, in light mode</title>
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor"
      stroke-width="1" stroke-linecap="round" stroke-linejoin="round"
      class="icon-custom-derived-from-feather-sun-and-tabler-moon">
      <path style="opacity: 50%" d="M 5.411 14.504 C 5.471 14.504 5.532 14.504 5.591 14.504 C 3.639 16.319 4.383 19.569 6.931 20.352 C 7.693 20.586 8.512 20.551 9.25 20.252 C 8.023 23.207 4.056 23.725 2.11 21.184 C 0.166 18.642 1.702 14.949 4.874 14.536 C 5.051 14.512 5.231 14.5 5.411 14.5 L 5.411 14.504 Z"/>
      <line x1="14.5" y1="3.25" x2="14.5" y2="1.25"/>
      <line x1="14.5" y1="15.85" x2="14.5" y2="17.85"/>
      <line x1="10.044" y1="5.094" x2="8.63" y2="3.68"/>
      <line x1="19" y1="14.05" x2="20.414" y2="15.464"/>
      <line x1="8.2" y1="9.55" x2="6.2" y2="9.55"/>
      <line x1="20.8" y1="9.55" x2="22.8" y2="9.55"/>
      <line x1="10.044" y1="14.006" x2="8.63" y2="15.42"/>
      <line x1="19" y1="5.05" x2="20.414" y2="3.636"/>
      <circle cx="14.5" cy="9.55" r="3.6"/>
    </svg>
  </symbol>
  <symbol id="svg-moon-with-sun" viewBox="0 0 24 24">
    <title>Auto light/dark, in dark mode</title>
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor"
      stroke-width="1" stroke-linecap="round" stroke-linejoin="round"
      class="icon-custom-derived-from-feather-sun-and-tabler-moon">
      <path d="M 8.282 7.007 C 8.385 7.007 8.494 7.007 8.595 7.007 C 5.18 10.184 6.481 15.869 10.942 17.24 C 12.275 17.648 13.706 17.589 15 17.066 C 12.851 22.236 5.91 23.143 2.505 18.696 C -0.897 14.249 1.791 7.786 7.342 7.063 C 7.652 7.021 7.965 7 8.282 7 L 8.282 7.007 Z"/>
      <line style="opacity: 50%" x1="18" y1="3.705" x2="18" y2="2.5"/>
      <line style="opacity: 50%" x1="18" y1="11.295" x2="18" y2="12.5"/>
      <line style="opacity: 50%" x1="15.316" y1="4.816" x2="14.464" y2="3.964"/>
      <line style="opacity: 50%" x1="20.711" y1="10.212" x2="21.563" y2="11.063"/>
      <line style="opacity: 50%" x1="14.205" y1="7.5" x2="13.001" y2="7.5"/>
      <line style="opacity: 50%" x1="21.795" y1="7.5" x2="23" y2="7.5"/>
      <line style="opacity: 50%" x1="15.316" y1="10.184" x2="14.464" y2="11.036"/>
      <line style="opacity: 50%" x1="20.711" y1="4.789" x2="21.563" y2="3.937"/>
      <circle style="opacity: 50%" cx="18" cy="7.5" r="2.169"/>
    </svg>
  </symbol>
  <symbol id="svg-pencil" viewBox="0 0 24 24">
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor"
      stroke-width="1" stroke-linecap="round" stroke-linejoin="round" class="icon-tabler-pencil-code">
      <path d="M4 20h4l10.5 -10.5a2.828 2.828 0 1 0 -4 -4l-10.5 10.5v4" />
      <path d="M13.5 6.5l4 4" />
      <path d="M20 21l2 -2l-2 -2" />
      <path d="M17 17l-2 2l2 2" /
    </svg>
  </symbol>
  <symbol id="svg-eye" viewBox="0 0 24 24">
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor"
      stroke-width="1" stroke-linecap="round" stroke-linejoin="round" class="icon-tabler-eye-code">
      <path stroke="none" d="M0 0h24v24H0z" fill="none" />
      <path d="M10 12a2 2 0 1 0 4 0a2 2 0 0 0 -4 0" />
      <path
        d="M11.11 17.958c-3.209 -.307 -5.91 -2.293 -8.11 -5.958c2.4 -4 5.4 -6 9 -6c3.6 0 6.6 2 9 6c-.21 .352 -.427 .688 -.647 1.008" />
      <path d="M20 21l2 -2l-2 -2" />
      <path d="M17 17l-2 2l2 2" />
    </svg>
  </symbol>
</svg>

<input type="checkbox" class="sidebar-toggle" name="__navigation" id="__navigation">
<input type="checkbox" class="sidebar-toggle" name="__toc" id="__toc">
<label class="overlay sidebar-overlay" for="__navigation">
  <div class="visually-hidden">Hide navigation sidebar</div>
</label>
<label class="overlay toc-overlay" for="__toc">
  <div class="visually-hidden">Hide table of contents sidebar</div>
</label>

<a class="skip-to-content muted-link" href="#furo-main-content">Skip to content</a>

<div class="announcement">
  <aside class="announcement-content">
     <em>Feedback welcomed 🎉 at <a href='http://xxx'>dummy url</a></em> 
  </aside>
</div>

<div class="page">
  <header class="mobile-header">
    <div class="header-left">
      <label class="nav-overlay-icon" for="__navigation">
        <div class="visually-hidden">Toggle site navigation sidebar</div>
        <i class="icon"><svg><use href="#svg-menu"></use></svg></i>
      </label>
    </div>
    <div class="header-center">
      <a href="../../index.html"><div class="brand">Documentation</div></a>
    </div>
    <div class="header-right">
      <div class="theme-toggle-container theme-toggle-header">
        <button class="theme-toggle">
          <div class="visually-hidden">Toggle Light / Dark / Auto color theme</div>
          <svg class="theme-icon-when-auto-light"><use href="#svg-sun-with-moon"></use></svg>
          <svg class="theme-icon-when-auto-dark"><use href="#svg-moon-with-sun"></use></svg>
          <svg class="theme-icon-when-dark"><use href="#svg-moon"></use></svg>
          <svg class="theme-icon-when-light"><use href="#svg-sun"></use></svg>
        </button>
      </div>
      <label class="toc-overlay-icon toc-header-icon" for="__toc">
        <div class="visually-hidden">Toggle table of contents sidebar</div>
        <i class="icon"><svg><use href="#svg-toc"></use></svg></i>
      </label>
    </div>
  </header>
  <aside class="sidebar-drawer">
    <div class="sidebar-container">
      
      <div class="sidebar-sticky"><a class="sidebar-brand" href="../../index.html">
  
  
  <span class="sidebar-brand-text">Documentation</span>
  
</a><form class="sidebar-search-container" method="get" action="../../search.html" role="search">
  <input class="sidebar-search" placeholder="Search" name="q" aria-label="Search">
  <input type="hidden" name="check_keywords" value="yes">
  <input type="hidden" name="area" value="default">
</form>
<div id="searchbox"></div><div class="sidebar-scroll"><div class="sidebar-tree">
  <p class="caption" role="heading"><span class="caption-text">Content</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../tutorial_installation.html">Installation</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../tutorial_dynamic_project.html">Dynamic Project</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">API Reference</span></p>
<ul class="current">
<li class="toctree-l1 current has-children"><a class="reference internal" href="../api.html">egrecho.core</a><input checked="" class="toctree-checkbox" id="toctree-checkbox-1" name="toctree-checkbox-1" role="switch" type="checkbox"/><label for="toctree-checkbox-1"><div class="visually-hidden">Toggle navigation of egrecho.core</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul class="current">
<li class="toctree-l2"><a class="reference internal" href="config.html">egrecho.core.config</a></li>
<li class="toctree-l2"><a class="reference internal" href="data_builder.html">egrecho.core.data_builder</a></li>
<li class="toctree-l2"><a class="reference internal" href="feature_extractor.html">egrecho.core.feature_extractor</a></li>
<li class="toctree-l2"><a class="reference internal" href="loads.html">egrecho.core.loads</a></li>
<li class="toctree-l2"><a class="reference internal" href="module.html">egrecho.core.module</a></li>
<li class="toctree-l2"><a class="reference internal" href="optimization.html">egrecho.core.optimization</a></li>
<li class="toctree-l2"><a class="reference internal" href="parser.html">egrecho.core.parser</a></li>
<li class="toctree-l2"><a class="reference internal" href="teacher.html">egrecho.core.teacher</a></li>
<li class="toctree-l2 current current-page"><a class="current reference internal" href="#">egrecho.core.tokenizer</a></li>
</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../api.html#egrecho-utils">egrecho.utils</a><input class="toctree-checkbox" id="toctree-checkbox-2" name="toctree-checkbox-2" role="switch" type="checkbox"/><label for="toctree-checkbox-2"><div class="visually-hidden">Toggle navigation of egrecho.utils</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../utils/index.html">egrecho.utils.apply</a></li>
<li class="toctree-l2"><a class="reference internal" href="../utils/index.html#module-egrecho.utils.common">egrecho.utils.common</a></li>
<li class="toctree-l2"><a class="reference internal" href="../utils/index.html#module-egrecho.utils.constants">egrecho.utils.constants</a></li>
<li class="toctree-l2"><a class="reference internal" href="../utils/index.html#module-egrecho.utils.cuda_utils">egrecho.utils.cuda_utils</a></li>
<li class="toctree-l2"><a class="reference internal" href="../utils/index.html#module-egrecho.utils.data_utils">egrecho.utils.data_utils</a></li>
<li class="toctree-l2"><a class="reference internal" href="../utils/index.html#module-egrecho.utils.dist">egrecho.utils.dist</a></li>
<li class="toctree-l2"><a class="reference internal" href="../utils/index.html#module-egrecho.utils.imports">egrecho.utils.imports</a></li>
<li class="toctree-l2"><a class="reference internal" href="../utils/index.html#module-egrecho.utils.logging">egrecho.utils.logging</a></li>
<li class="toctree-l2"><a class="reference internal" href="../utils/index.html#module-egrecho.utils.mask">egrecho.utils.mask</a></li>
<li class="toctree-l2"><a class="reference internal" href="../utils/index.html#module-egrecho.utils.misc">egrecho.utils.misc</a></li>
<li class="toctree-l2"><a class="reference internal" href="../utils/index.html#module-egrecho.utils.register">egrecho.utils.register</a></li>
<li class="toctree-l2"><a class="reference internal" href="../utils/index.html#module-egrecho.utils.torch_utils">egrecho.utils.torch_utils</a></li>
<li class="toctree-l2"><a class="reference internal" href="../utils/index.html#module-egrecho.utils.types">egrecho.utils.types</a></li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../utils/index.html#egrecho-utils-dummy">egrecho.utils.dummy</a><input class="toctree-checkbox" id="toctree-checkbox-3" name="toctree-checkbox-3" role="switch" type="checkbox"/><label for="toctree-checkbox-3"><div class="visually-hidden">Toggle navigation of egrecho.utils.dummy</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l3"><a class="reference internal" href="../utils/egrecho.utils.dummy.html">egrecho.utils.dummy.generate</a></li>
</ul>
</li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../utils/index.html#egrecho-utils-io">egrecho.utils.io</a><input class="toctree-checkbox" id="toctree-checkbox-4" name="toctree-checkbox-4" role="switch" type="checkbox"/><label for="toctree-checkbox-4"><div class="visually-hidden">Toggle navigation of egrecho.utils.io</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l3"><a class="reference internal" href="../utils/egrecho.utils.io.html">egrecho.utils.io.files</a></li>
<li class="toctree-l3"><a class="reference internal" href="../utils/egrecho.utils.io.html#module-egrecho.utils.io.kaldi">egrecho.utils.io.kaldi</a></li>
<li class="toctree-l3"><a class="reference internal" href="../utils/egrecho.utils.io.html#module-egrecho.utils.io.reader">egrecho.utils.io.reader</a></li>
<li class="toctree-l3"><a class="reference internal" href="../utils/egrecho.utils.io.html#module-egrecho.utils.io.resolve_ckpt">egrecho.utils.io.resolve_ckpt</a></li>
<li class="toctree-l3"><a class="reference internal" href="../utils/egrecho.utils.io.html#module-egrecho.utils.io.utils">egrecho.utils.io.utils</a></li>
<li class="toctree-l3"><a class="reference internal" href="../utils/egrecho.utils.io.html#module-egrecho.utils.io.writer">egrecho.utils.io.writer</a></li>
</ul>
</li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../utils/index.html#egrecho-utils-patch">egrecho.utils.patch</a><input class="toctree-checkbox" id="toctree-checkbox-5" name="toctree-checkbox-5" role="switch" type="checkbox"/><label for="toctree-checkbox-5"><div class="visually-hidden">Toggle navigation of egrecho.utils.patch</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l3"><a class="reference internal" href="../utils/egrecho.utils.patch.html">egrecho.utils.patch.io_patch</a></li>
<li class="toctree-l3"><a class="reference internal" href="../utils/egrecho.utils.patch.html#module-egrecho.utils.patch.torchdata_patch">egrecho.utils.patch.torchdata_patch</a></li>
<li class="toctree-l3 has-children"><a class="reference internal" href="../utils/egrecho.utils.patch.html#egrecho-utils-patch-simple-parse-patch">egrecho.utils.patch.simple_parse_patch</a><input class="toctree-checkbox" id="toctree-checkbox-6" name="toctree-checkbox-6" role="switch" type="checkbox"/><label for="toctree-checkbox-6"><div class="visually-hidden">Toggle navigation of egrecho.utils.patch.simple_parse_patch</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l4"><a class="reference internal" href="../utils/egrecho.utils.patch.simple_parse_patch.html">egrecho.utils.patch.simple_parse_patch._utils</a></li>
<li class="toctree-l4"><a class="reference internal" href="../utils/egrecho.utils.patch.simple_parse_patch.html#module-egrecho.utils.patch.simple_parse_patch.decoding">egrecho.utils.patch.simple_parse_patch.decoding</a></li>
<li class="toctree-l4"><a class="reference internal" href="../utils/egrecho.utils.patch.simple_parse_patch.html#module-egrecho.utils.patch.simple_parse_patch.serializable">egrecho.utils.patch.simple_parse_patch.serializable</a></li>
<li class="toctree-l4 has-children"><a class="reference internal" href="../utils/egrecho.utils.patch.simple_parse_patch.html#egrecho-utils-patch-simple-parse-patch-annotation-utils">egrecho.utils.patch.simple_parse_patch.annotation_utils</a><input class="toctree-checkbox" id="toctree-checkbox-7" name="toctree-checkbox-7" role="switch" type="checkbox"/><label for="toctree-checkbox-7"><div class="visually-hidden">Toggle navigation of egrecho.utils.patch.simple_parse_patch.annotation_utils</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l5"><a class="reference internal" href="../utils/egrecho.utils.patch.simple_parse_patch.annotation_utils.html">egrecho.utils.patch.simple_parse_patch.annotation_utils</a></li>
<li class="toctree-l5"><a class="reference internal" href="../utils/egrecho.utils.patch.simple_parse_patch.annotation_utils.html#module-egrecho.utils.patch.simple_parse_patch.annotation_utils.get_field_annotations">egrecho.utils.patch.simple_parse_patch.annotation_utils.get_field_annotations</a></li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../utils/index.html#egrecho-utils-seeder">egrecho.utils.seeder</a><input class="toctree-checkbox" id="toctree-checkbox-8" name="toctree-checkbox-8" role="switch" type="checkbox"/><label for="toctree-checkbox-8"><div class="visually-hidden">Toggle navigation of egrecho.utils.seeder</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l3"><a class="reference internal" href="../utils/egrecho.utils.seeder.html">egrecho.utils.seeder.seed</a></li>
</ul>
</li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../utils/index.html#egrecho-utils-text">egrecho.utils.text</a><input class="toctree-checkbox" id="toctree-checkbox-9" name="toctree-checkbox-9" role="switch" type="checkbox"/><label for="toctree-checkbox-9"><div class="visually-hidden">Toggle navigation of egrecho.utils.text</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l3"><a class="reference internal" href="../utils/egrecho.utils.text.html">egrecho.utils.text.cleaners</a></li>
<li class="toctree-l3"><a class="reference internal" href="../utils/egrecho.utils.text.html#module-egrecho.utils.text.number_cn">egrecho.utils.text.number_cn</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../api.html#egrecho-pipeline">egrecho.pipeline</a><input class="toctree-checkbox" id="toctree-checkbox-10" name="toctree-checkbox-10" role="switch" type="checkbox"/><label for="toctree-checkbox-10"><div class="visually-hidden">Toggle navigation of egrecho.pipeline</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../pipeline/index.html">egrecho.pipeline.base</a></li>
<li class="toctree-l2"><a class="reference internal" href="../pipeline/index.html#module-egrecho.pipeline.speaker_embedding">egrecho.pipeline.speaker_embedding</a></li>
</ul>
</li>
</ul>

</div>
</div>

      </div>
      
    </div>
  </aside>
  <div class="main">
    <div class="content">
      <div class="article-container">
        <a href="#" class="back-to-top muted-link">
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24">
            <path d="M13 20h-2V8l-5.5 5.5-1.42-1.42L12 4.16l7.92 7.92-1.42 1.42L13 8v12z"></path>
          </svg>
          <span>Back to top</span>
        </a>
        <div class="content-icon-container">
          <div class="view-this-page">
  <a class="muted-link" href="https://github.com/wangers/subtools2/blob/master/docs/source/api/core/tokenizer.md?plain=true" title="View this page">
    <svg><use href="#svg-eye"></use></svg>
    <span class="visually-hidden">View this page</span>
  </a>
</div><div class="edit-this-page">
  <a class="muted-link" href="https://github.com/wangers/subtools2/edit/master/docs/source/api/core/tokenizer.md" title="Edit this page">
    <svg><use href="#svg-pencil"></use></svg>
    <span class="visually-hidden">Edit this page</span>
  </a>
</div><div class="theme-toggle-container theme-toggle-content">
            <button class="theme-toggle">
              <div class="visually-hidden">Toggle Light / Dark / Auto color theme</div>
              <svg class="theme-icon-when-auto-light"><use href="#svg-sun-with-moon"></use></svg>
              <svg class="theme-icon-when-auto-dark"><use href="#svg-moon-with-sun"></use></svg>
              <svg class="theme-icon-when-dark"><use href="#svg-moon"></use></svg>
              <svg class="theme-icon-when-light"><use href="#svg-sun"></use></svg>
            </button>
          </div>
          <label class="toc-overlay-icon toc-content-icon" for="__toc">
            <div class="visually-hidden">Toggle table of contents sidebar</div>
            <i class="icon"><svg><use href="#svg-toc"></use></svg></i>
          </label>
        </div>
        <article role="main" id="furo-main-content">
          <section id="module-egrecho.core.tokenizer">
<span id="egrecho-core-tokenizer"></span><h1>egrecho.core.tokenizer<a class="headerlink" href="#module-egrecho.core.tokenizer" title="Permalink to this heading">#</a></h1>
<dl class="py class">
<dt class="sig sig-object py" id="egrecho.core.tokenizer.TruncationStrategy">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">egrecho.core.tokenizer.</span></span><span class="sig-name descname"><span class="pre">TruncationStrategy</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">value</span></span></em><span class="sig-paren">)</span><a class="reference external" href="https://github.com/wangers/subtools2/tree/master/egrecho/core/tokenizer.py#L57-L66"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#egrecho.core.tokenizer.TruncationStrategy" title="Permalink to this definition">#</a></dt>
<dd><p>Bases: <a class="reference internal" href="../utils/index.html#egrecho.utils.types.StrEnum" title="egrecho.utils.types.StrEnum"><code class="xref py py-class docutils literal notranslate"><span class="pre">StrEnum</span></code></a></p>
<p>Possible values for the <code class="docutils literal notranslate"><span class="pre">truncation</span></code> argument in <a class="reference internal" href="#egrecho.core.tokenizer.Tokenizer.__call__" title="egrecho.core.tokenizer.Tokenizer.__call__"><code class="xref py py-meth docutils literal notranslate"><span class="pre">Tokenizer.__call__()</span></code></a>. Useful for tab-completion in
an IDE.</p>
</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="egrecho.core.tokenizer.TensorType">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">egrecho.core.tokenizer.</span></span><span class="sig-name descname"><span class="pre">TensorType</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">value</span></span></em><span class="sig-paren">)</span><a class="reference external" href="https://github.com/wangers/subtools2/tree/master/egrecho/core/tokenizer.py#L69-L73"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#egrecho.core.tokenizer.TensorType" title="Permalink to this definition">#</a></dt>
<dd><p>Bases: <a class="reference internal" href="../utils/index.html#egrecho.utils.types.StrEnum" title="egrecho.utils.types.StrEnum"><code class="xref py py-class docutils literal notranslate"><span class="pre">StrEnum</span></code></a></p>
<p>For tab-completion in an IDE.</p>
</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="egrecho.core.tokenizer.BaseTokenizerConfig">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">egrecho.core.tokenizer.</span></span><span class="sig-name descname"><span class="pre">BaseTokenizerConfig</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">extradir</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference external" href="https://github.com/wangers/subtools2/tree/master/egrecho/core/tokenizer.py#L77-L217"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#egrecho.core.tokenizer.BaseTokenizerConfig" title="Permalink to this definition">#</a></dt>
<dd><p>Bases: <a class="reference internal" href="config.html#egrecho.core.config.DataclassConfig" title="egrecho.core.config.DataclassConfig"><code class="xref py py-class docutils literal notranslate"><span class="pre">DataclassConfig</span></code></a></p>
<p>Base class for the <a class="reference internal" href="#egrecho.core.tokenizer.BaseTokenizer" title="egrecho.core.tokenizer.BaseTokenizer"><code class="xref py py-class docutils literal notranslate"><span class="pre">BaseTokenizer</span></code></a> configuration.</p>
<p>The path <code class="xref py py-attr docutils literal notranslate"><span class="pre">extradir</span></code> will <strong>not</strong> be serialized in the config file. When deserialized from
a config file (tokenizer_config.json), it will be set to the directory of the config file by default,
allowing for the locationing of files defined by <a class="reference internal" href="#egrecho.core.tokenizer.BaseTokenizerConfig.extra_files_names" title="egrecho.core.tokenizer.BaseTokenizerConfig.extra_files_names"><code class="xref py py-meth docutils literal notranslate"><span class="pre">extra_files_names()</span></code></a>.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>extradir</strong> (<em>Optional</em><em>[</em><em>Union</em><em>[</em><em>str</em><em>, </em><em>Path</em><em>]</em><em>]</em>) -- Path to the directory containing vocabulary files defined by :meth:<code class="docutils literal notranslate"><span class="pre">extra_files_names</span></code>.</p>
</dd>
</dl>
<dl class="py property">
<dt class="sig sig-object py" id="egrecho.core.tokenizer.BaseTokenizerConfig.extra_files_names">
<em class="property"><span class="pre">property</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">extra_files_names</span></span><a class="headerlink" href="#egrecho.core.tokenizer.BaseTokenizerConfig.extra_files_names" title="Permalink to this definition">#</a></dt>
<dd><p>Defines the extra file names required by the model. Can be either:</p>
<ul class="simple">
<li><p>A dictionary with values being the filenames for saving the associated files (strings).</p></li>
<li><p>A tuple/list of filenames.</p></li>
</ul>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="egrecho.core.tokenizer.BaseTokenizerConfig.get_extra_files">
<span class="sig-name descname"><span class="pre">get_extra_files</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">extra_files_names</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">check_local_exist</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em><span class="sig-paren">)</span><a class="reference external" href="https://github.com/wangers/subtools2/tree/master/egrecho/core/tokenizer.py#L102-L117"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#egrecho.core.tokenizer.BaseTokenizerConfig.get_extra_files" title="Permalink to this definition">#</a></dt>
<dd><p>Recursively adds prefix dir to locate extra files.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="egrecho.core.tokenizer.BaseTokenizerConfig.from_cfg_dir">
<em class="property"><span class="pre">classmethod</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">from_cfg_dir</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">srcdir</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="reference external" href="https://github.com/wangers/subtools2/tree/master/egrecho/core/tokenizer.py#L119-L139"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#egrecho.core.tokenizer.BaseTokenizerConfig.from_cfg_dir" title="Permalink to this definition">#</a></dt>
<dd><p>Instantiate a :class:<code class="docutils literal notranslate"><span class="pre">BaseTokenizerConfig</span></code> (or a derived class).</p>
<dl class="field-list simple">
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><span class="sphinx_autodoc_typehints-type"><a class="reference internal" href="#egrecho.core.tokenizer.BaseTokenizerConfig" title="egrecho.core.tokenizer.BaseTokenizerConfig"><code class="xref py py-class docutils literal notranslate"><span class="pre">BaseTokenizerConfig</span></code></a></span></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="egrecho.core.tokenizer.BaseTokenizerConfig.copy_extras">
<span class="sig-name descname"><span class="pre">copy_extras</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">savedir</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">extra_files_names</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">filename_prefix</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">excludes</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="reference external" href="https://github.com/wangers/subtools2/tree/master/egrecho/core/tokenizer.py#L141-L201"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#egrecho.core.tokenizer.BaseTokenizerConfig.copy_extras" title="Permalink to this definition">#</a></dt>
<dd><p>Copys the extra files of the tokenizer config.</p>
<p>Use :meth:<code class="docutils literal notranslate"><span class="pre">BaseTokenizer.save_to</span></code> to save the whole configuration
(config file + extra files) of the tokenizer. This method will copy all files
defined by :meth:<code class="docutils literal notranslate"><span class="pre">extra_files_names</span></code> by defaults.
:type savedir: 
:param savedir: The directory in which to save the extra files.
:type savedir: <code class="docutils literal notranslate"><span class="pre">str</span></code>
:type extra_files_names: 
:param extra_files_names: If None, use default files defined by class property <cite>extra_files_names</cite>
:type filename_prefix: 
:param filename_prefix: An optional prefix to add to the named of the saved files.
:type filename_prefix: <code class="docutils literal notranslate"><span class="pre">str</span></code>, <em>optional</em>
:type excludes: <span class="sphinx_autodoc_typehints-type"><code class="xref py py-data docutils literal notranslate"><span class="pre">Union</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">str</span></code>, <code class="xref py py-class docutils literal notranslate"><span class="pre">List</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">str</span></code>], <code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code>]</span>
:param excludes: Excludes what fnames.
:type excludes: Union[<code class="docutils literal notranslate"><span class="pre">str</span></code>, <code class="docutils literal notranslate"><span class="pre">List[str]</span></code>]</p>
<dl class="field-list simple">
<dt class="field-odd">Returns<span class="colon">:</span></dt>
<dd class="field-odd"><p>Paths to the files saved.</p>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p><code class="docutils literal notranslate"><span class="pre">Tuple(str)</span></code></p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="egrecho.core.tokenizer.BaseTokenizer">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">egrecho.core.tokenizer.</span></span><span class="sig-name descname"><span class="pre">BaseTokenizer</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">config</span></span></em><span class="sig-paren">)</span><a class="reference external" href="https://github.com/wangers/subtools2/tree/master/egrecho/core/tokenizer.py#L220-L459"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#egrecho.core.tokenizer.BaseTokenizer" title="Permalink to this definition">#</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">ABC</span></code></p>
<p>A base class offers serialize methods for tokenizer. and derived classes should implement its
encode/decode methods (:meth:<code class="docutils literal notranslate"><span class="pre">text2ids</span></code>, :meth:<code class="docutils literal notranslate"><span class="pre">ids2text</span></code>, etc..)</p>
<p>The implementation of the tokenizer method is intended for derived classes.
Its purpose is to facilitate coordination between model inputs and the frontend data processor.</p>
<p>Unlike :class:<code class="docutils literal notranslate"><span class="pre">egrecho.core.feature_extractor.speaker.BaseFeature</span></code>, which is designed to save
its mainly attributes as config itself. :class:<code class="docutils literal notranslate"><span class="pre">BaseTokenizer</span></code> maintains an inside :attr:<code class="docutils literal notranslate"><span class="pre">config</span></code> instance.</p>
<p>Class attributes (overridden by derived classes)</p>
<blockquote>
<div><ul class="simple">
<li><p><strong>CONFIG_CLS</strong> -- The type of assosiate :class:<code class="docutils literal notranslate"><span class="pre">BaseTokenizerConfig</span></code> (or a derived class).</p></li>
</ul>
</div></blockquote>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>config</strong> (<a class="reference internal" href="#egrecho.core.tokenizer.BaseTokenizerConfig" title="egrecho.core.tokenizer.BaseTokenizerConfig"><em>BaseTokenizerConfig</em></a>) -- configuration object.</p>
</dd>
</dl>
<dl class="py property">
<dt class="sig sig-object py" id="egrecho.core.tokenizer.BaseTokenizer.cls">
<em class="property"><span class="pre">property</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">cls</span></span><a class="headerlink" href="#egrecho.core.tokenizer.BaseTokenizer.cls" title="Permalink to this definition">#</a></dt>
<dd><p>Returns cls_id if available.</p>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="egrecho.core.tokenizer.BaseTokenizer.sep">
<em class="property"><span class="pre">property</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">sep</span></span><a class="headerlink" href="#egrecho.core.tokenizer.BaseTokenizer.sep" title="Permalink to this definition">#</a></dt>
<dd><p>Returns sep_id if available.</p>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="egrecho.core.tokenizer.BaseTokenizer.pad">
<em class="property"><span class="pre">property</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">pad</span></span><a class="headerlink" href="#egrecho.core.tokenizer.BaseTokenizer.pad" title="Permalink to this definition">#</a></dt>
<dd><p>Returns pad_id if available.</p>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="egrecho.core.tokenizer.BaseTokenizer.pad_token_id">
<em class="property"><span class="pre">property</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">pad_token_id</span></span><a class="headerlink" href="#egrecho.core.tokenizer.BaseTokenizer.pad_token_id" title="Permalink to this definition">#</a></dt>
<dd><p>Returns pad_id if available.</p>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="egrecho.core.tokenizer.BaseTokenizer.pad_token_type_id">
<em class="property"><span class="pre">property</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">pad_token_type_id</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">int</span></em><a class="headerlink" href="#egrecho.core.tokenizer.BaseTokenizer.pad_token_type_id" title="Permalink to this definition">#</a></dt>
<dd><p>Id of the padding token type in the vocabulary.</p>
<dl class="field-list simple">
<dt class="field-odd">Type<span class="colon">:</span></dt>
<dd class="field-odd"><p><code class="docutils literal notranslate"><span class="pre">int</span></code></p>
</dd>
</dl>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="egrecho.core.tokenizer.BaseTokenizer.eod">
<em class="property"><span class="pre">property</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">eod</span></span><a class="headerlink" href="#egrecho.core.tokenizer.BaseTokenizer.eod" title="Permalink to this definition">#</a></dt>
<dd><p>Returns eod_id if available.</p>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="egrecho.core.tokenizer.BaseTokenizer.bos">
<em class="property"><span class="pre">property</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">bos</span></span><a class="headerlink" href="#egrecho.core.tokenizer.BaseTokenizer.bos" title="Permalink to this definition">#</a></dt>
<dd><p>Returns bos_id if available.</p>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="egrecho.core.tokenizer.BaseTokenizer.eos">
<em class="property"><span class="pre">property</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">eos</span></span><a class="headerlink" href="#egrecho.core.tokenizer.BaseTokenizer.eos" title="Permalink to this definition">#</a></dt>
<dd><p>Returns eos_id if available.</p>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="egrecho.core.tokenizer.BaseTokenizer.mask">
<em class="property"><span class="pre">property</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">mask</span></span><a class="headerlink" href="#egrecho.core.tokenizer.BaseTokenizer.mask" title="Permalink to this definition">#</a></dt>
<dd><p>Returns mask_id if available.</p>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="egrecho.core.tokenizer.BaseTokenizer.all_special_ids">
<em class="property"><span class="pre">property</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">all_special_ids</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">List</span><span class="p"><span class="pre">[</span></span><span class="pre">int</span><span class="p"><span class="pre">]</span></span></em><a class="headerlink" href="#egrecho.core.tokenizer.BaseTokenizer.all_special_ids" title="Permalink to this definition">#</a></dt>
<dd><p>List the ids of the special tokens(<cite>‘&lt;unk&gt;’</cite>, <cite>‘&lt;cls&gt;’</cite>, etc.) mapped to class attributes.</p>
<dl class="field-list simple">
<dt class="field-odd">Type<span class="colon">:</span></dt>
<dd class="field-odd"><p><cite>List[int]</cite></p>
</dd>
</dl>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="egrecho.core.tokenizer.BaseTokenizer.vocab_size">
<em class="property"><span class="pre">property</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">vocab_size</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">int</span></em><a class="headerlink" href="#egrecho.core.tokenizer.BaseTokenizer.vocab_size" title="Permalink to this definition">#</a></dt>
<dd><p>Size of the base vocabulary (without the added tokens).</p>
<dl class="field-list simple">
<dt class="field-odd">Type<span class="colon">:</span></dt>
<dd class="field-odd"><p><code class="docutils literal notranslate"><span class="pre">int</span></code></p>
</dd>
</dl>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="egrecho.core.tokenizer.BaseTokenizer.config">
<em class="property"><span class="pre">property</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">config</span></span><a class="headerlink" href="#egrecho.core.tokenizer.BaseTokenizer.config" title="Permalink to this definition">#</a></dt>
<dd><p>Refs config</p>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="egrecho.core.tokenizer.BaseTokenizer.extradir">
<em class="property"><span class="pre">property</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">extradir</span></span><a class="headerlink" href="#egrecho.core.tokenizer.BaseTokenizer.extradir" title="Permalink to this definition">#</a></dt>
<dd><p>Refs extra files directory.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="egrecho.core.tokenizer.BaseTokenizer.from_cfg_dir">
<em class="property"><span class="pre">classmethod</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">from_cfg_dir</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">srcdir</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="reference external" href="https://github.com/wangers/subtools2/tree/master/egrecho/core/tokenizer.py#L390-L401"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#egrecho.core.tokenizer.BaseTokenizer.from_cfg_dir" title="Permalink to this definition">#</a></dt>
<dd><p>Instantiate a :class:<code class="docutils literal notranslate"><span class="pre">BaseTokenizer</span></code> (or a derived class) from a
dir has config files.</p>
<dl class="field-list simple">
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><span class="sphinx_autodoc_typehints-type"><a class="reference internal" href="#egrecho.core.tokenizer.BaseTokenizer" title="egrecho.core.tokenizer.BaseTokenizer"><code class="xref py py-class docutils literal notranslate"><span class="pre">BaseTokenizer</span></code></a></span></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="egrecho.core.tokenizer.BaseTokenizer.save_to">
<span class="sig-name descname"><span class="pre">save_to</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">savedir</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">filename_prefix</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="reference external" href="https://github.com/wangers/subtools2/tree/master/egrecho/core/tokenizer.py#L403-L425"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#egrecho.core.tokenizer.BaseTokenizer.save_to" title="Permalink to this definition">#</a></dt>
<dd><p>Saves the whole configuration (config file + extra files) of the tokenizer</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>savedir</strong> (<code class="docutils literal notranslate"><span class="pre">str</span></code>) -- The directory in which to save the extra files.</p></li>
<li><p><strong>filename_prefix</strong> (<code class="docutils literal notranslate"><span class="pre">str</span></code>, <em>optional</em>) -- An optional prefix to add to the named of the saved files.</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="egrecho.core.tokenizer.BaseTokenizer.save_config">
<span class="sig-name descname"><span class="pre">save_config</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">path</span></span></em><span class="sig-paren">)</span><a class="reference external" href="https://github.com/wangers/subtools2/tree/master/egrecho/core/tokenizer.py#L427-L435"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#egrecho.core.tokenizer.BaseTokenizer.save_config" title="Permalink to this definition">#</a></dt>
<dd><p>save the configuration to a file.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>path</strong> (<em>Union</em><em>[</em><em>Path</em><em>, </em><em>str</em><em>]</em>) -- The path of the output file.</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="egrecho.core.tokenizer.BaseTokenizer.save_extras">
<span class="sig-name descname"><span class="pre">save_extras</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">savedir</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">filename_prefix</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference external" href="https://github.com/wangers/subtools2/tree/master/egrecho/core/tokenizer.py#L437-L441"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#egrecho.core.tokenizer.BaseTokenizer.save_extras" title="Permalink to this definition">#</a></dt>
<dd><p>Derived classes should overwrite it for special savings.</p>
<dl class="field-list simple">
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><span class="sphinx_autodoc_typehints-type"><code class="xref py py-data docutils literal notranslate"><span class="pre">Tuple</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">str</span></code>]</span></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="egrecho.core.tokenizer.BaseTokenizer.default_save_extras">
<span class="sig-name descname"><span class="pre">default_save_extras</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">savedir</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">filename_prefix</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">excludes</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="reference external" href="https://github.com/wangers/subtools2/tree/master/egrecho/core/tokenizer.py#L443-L456"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#egrecho.core.tokenizer.BaseTokenizer.default_save_extras" title="Permalink to this definition">#</a></dt>
<dd><p>A default funtion conviniently copies extra files.</p>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="egrecho.core.tokenizer.Tokenizer">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">egrecho.core.tokenizer.</span></span><span class="sig-name descname"><span class="pre">Tokenizer</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">config</span></span></em><span class="sig-paren">)</span><a class="reference external" href="https://github.com/wangers/subtools2/tree/master/egrecho/core/tokenizer.py#L557-L1724"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#egrecho.core.tokenizer.Tokenizer" title="Permalink to this definition">#</a></dt>
<dd><p>Bases: <a class="reference internal" href="#egrecho.core.tokenizer.BaseTokenizer" title="egrecho.core.tokenizer.BaseTokenizer"><code class="xref py py-class docutils literal notranslate"><span class="pre">BaseTokenizer</span></code></a></p>
<p>A base class aims to prepare model inputs via __call__ interface , derived from <a class="reference internal" href="#egrecho.core.tokenizer.BaseTokenizer" title="egrecho.core.tokenizer.BaseTokenizer"><code class="xref py py-class docutils literal notranslate"><span class="pre">BaseTokenizer</span></code></a>.
And offers some useful methods for padding/truncate. Core methods:</p>
<ul>
<li><p><a class="reference internal" href="#egrecho.core.tokenizer.Tokenizer.__call__" title="egrecho.core.tokenizer.Tokenizer.__call__"><code class="xref py py-meth docutils literal notranslate"><span class="pre">__call__()</span></code></a>:
Abstract method to tokenize and prepare for the model, can handle single or batch inputs.</p></li>
<li><p><a class="reference internal" href="#egrecho.core.tokenizer.Tokenizer.prepare_for_model" title="egrecho.core.tokenizer.Tokenizer.prepare_for_model"><code class="xref py py-meth docutils literal notranslate"><span class="pre">prepare_for_model()</span></code></a> (<strong>one sample</strong>):
Prepares a sequence of input id (tokenized by the <code class="xref py py-meth docutils literal notranslate"><span class="pre">text2ids()</span></code>), or a pair of sequences of inputs ids so
that it can be used by the model. Workflows typically follows:</p>
<blockquote>
<div><ul>
<li><p>Pre-define settings: Get truncate/pad strategy. Computes the total size of the returned encodings
via :meth:<code class="docutils literal notranslate"><span class="pre">num_special_tokens_to_add</span></code>. Which default hacks building
empty input ids through :meth:<code class="docutils literal notranslate"><span class="pre">build_inputs_with_special_tokens</span></code>.</p></li>
<li><p>Truncates: :meth:<code class="docutils literal notranslate"><span class="pre">truncate_sequences</span></code>.</p></li>
<li><p>Add special tokens like eos/sos, the list method should be overriden in a subclass:</p>
<blockquote>
<div><ul class="simple">
<li><p>:meth:<code class="docutils literal notranslate"><span class="pre">build_inputs_with_special_tokens</span></code>: Build model inputs from given ids.</p></li>
<li><p>:meth:<code class="docutils literal notranslate"><span class="pre">create_token_type_ids_from_sequences</span></code>: Create the token type IDs corresponding to the sequences.</p></li>
</ul>
</div></blockquote>
</li>
<li><p>Pad: pad a sample use :meth:<code class="docutils literal notranslate"><span class="pre">pad</span></code>.</p></li>
</ul>
</div></blockquote>
</li>
<li><p><a class="reference internal" href="#egrecho.core.tokenizer.Tokenizer.batch_decode" title="egrecho.core.tokenizer.Tokenizer.batch_decode"><code class="xref py py-meth docutils literal notranslate"><span class="pre">batch_decode()</span></code></a> / <a class="reference internal" href="#egrecho.core.tokenizer.Tokenizer.decode" title="egrecho.core.tokenizer.Tokenizer.decode"><code class="xref py py-meth docutils literal notranslate"><span class="pre">decode()</span></code></a>: inverse of <a class="reference internal" href="#egrecho.core.tokenizer.Tokenizer.__call__" title="egrecho.core.tokenizer.Tokenizer.__call__"><code class="xref py py-meth docutils literal notranslate"><span class="pre">__call__()</span></code></a>, depends on <code class="xref py py-meth docutils literal notranslate"><span class="pre">_decode()</span></code> in subclasses.</p></li>
</ul>
<p>Class attributes (overridden by derived classes)</p>
<blockquote>
<div><ul class="simple">
<li><p><strong>CONFIG_CLS</strong> -- The type of assosiate <a class="reference internal" href="#egrecho.core.tokenizer.BaseTokenizerConfig" title="egrecho.core.tokenizer.BaseTokenizerConfig"><code class="xref py py-class docutils literal notranslate"><span class="pre">BaseTokenizerConfig</span></code></a> (or a derived class).</p></li>
<li><p><strong>model_input_names</strong> (<code class="docutils literal notranslate"><span class="pre">List[str]</span></code>) -- A list of inputs expected in the forward pass of the model.</p></li>
<li><p><strong>padding_side</strong> (<code class="docutils literal notranslate"><span class="pre">str</span></code>) -- The default value for the side on which the model should have padding applied.
Should be <code class="docutils literal notranslate"><span class="pre">'right'</span></code> or <code class="docutils literal notranslate"><span class="pre">'left'</span></code>.</p></li>
<li><p><strong>truncation_side</strong> (<code class="docutils literal notranslate"><span class="pre">str</span></code>) -- The default value for the side on which the model should have truncation
applied. Should be <code class="docutils literal notranslate"><span class="pre">'right'</span></code> or <code class="docutils literal notranslate"><span class="pre">'left'</span></code>.</p></li>
</ul>
</div></blockquote>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Heavily borrowed and adapted from tokenizer module in <a class="reference external" href="https://github.com/huggingface/transformers/blob/main/src/transformers/tokenization_utils_base.py">huggingface tokenizer</a>.</p>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>config</strong> (<span class="sphinx_autodoc_typehints-type"><a class="reference internal" href="#egrecho.core.tokenizer.BaseTokenizerConfig" title="egrecho.core.tokenizer.BaseTokenizerConfig"><code class="xref py py-class docutils literal notranslate"><span class="pre">BaseTokenizerConfig</span></code></a></span>) -- configuration object derived from <a class="reference internal" href="#egrecho.core.tokenizer.BaseTokenizerConfig" title="egrecho.core.tokenizer.BaseTokenizerConfig"><code class="xref py py-class docutils literal notranslate"><span class="pre">BaseTokenizerConfig</span></code></a>.</p>
</dd>
</dl>
<dl class="py method">
<dt class="sig sig-object py" id="egrecho.core.tokenizer.Tokenizer.input_text_batched">
<em class="property"><span class="pre">classmethod</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">input_text_batched</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">text</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">text_pair</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">is_split_into_words</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span><a class="reference external" href="https://github.com/wangers/subtools2/tree/master/egrecho/core/tokenizer.py#L675-L693"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#egrecho.core.tokenizer.Tokenizer.input_text_batched" title="Permalink to this definition">#</a></dt>
<dd><p>Detect inputs text is valid batched.</p>
<dl class="field-list simple">
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><span class="sphinx_autodoc_typehints-type"><code class="xref py py-class docutils literal notranslate"><span class="pre">bool</span></code></span></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="egrecho.core.tokenizer.Tokenizer.__call__">
<span class="sig-name descname"><span class="pre">__call__</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">text</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">text_pair</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">add_special_tokens</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">padding</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">truncation</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">max_length</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">is_split_into_words</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="reference external" href="https://github.com/wangers/subtools2/tree/master/egrecho/core/tokenizer.py#L695-L781"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#egrecho.core.tokenizer.Tokenizer.__call__" title="Permalink to this definition">#</a></dt>
<dd><p>Main abstract method to tokenize and prepare for the model one or several sequence(s) or one or several pair(s) of
sequences. Below lists a possible format of inputs.</p>
<div class="admonition tip">
<p class="admonition-title">Tip</p>
<p>A preferred paradigm of inputs:</p>
<ul class="simple">
<li><dl class="simple">
<dt><code class="docutils literal notranslate"><span class="pre">is_split_into_words=False</span></code>, input text as follows:</dt><dd><ul>
<li><p>List[List[str]]: list with a list of strings, <strong>batch</strong> of tokenized tokens, i.e., need tokens2ids.</p></li>
<li><p>List[str]: list of strings, <strong>batch</strong> of strings, i.e., need text2ids.</p></li>
<li><p>str: <strong>single</strong> string, i.e., need directly text2ids.</p></li>
</ul>
</dd>
</dl>
</li>
<li><dl class="simple">
<dt><code class="docutils literal notranslate"><span class="pre">is_split_into_words=True</span></code>, input text as follows:</dt><dd><ul>
<li><p>List[List[str]]: list with a list of strings, <strong>batch</strong> of pretokenized (not tokenized but splited), i.e., need text2ids in inner list.</p></li>
<li><p>List[str]: list of strings, <strong>single</strong> pretokenized, i.e., need text2ids one by one.</p></li>
<li><p>str: <strong>single</strong> string, auto fallback to is_split_into_words=False.</p></li>
</ul>
</dd>
</dl>
</li>
</ul>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>text</strong> (<code class="docutils literal notranslate"><span class="pre">str</span></code>, <code class="docutils literal notranslate"><span class="pre">List[str]</span></code>, <code class="docutils literal notranslate"><span class="pre">List[List[str]]</span></code>, <em>optional</em>) -- The sequence or batch of sequences to be encoded. Each sequence can be a string or a list of strings
(pretokenized string). If the sequences are provided as list of strings (pretokenized), you must set
<code class="docutils literal notranslate"><span class="pre">is_split_into_words=True</span></code> (to lift the ambiguity with a batch of sequences).</p></li>
<li><p><strong>text_pair</strong> (<code class="docutils literal notranslate"><span class="pre">str</span></code>, <code class="docutils literal notranslate"><span class="pre">List[str]</span></code>, <code class="docutils literal notranslate"><span class="pre">List[List[str]]</span></code>, <em>optional</em>) -- The sequence or batch of sequences to be encoded. Each sequence can be a string or a list of strings
(pretokenized string). If the sequences are provided as list of strings (pretokenized), you must set
<code class="docutils literal notranslate"><span class="pre">is_split_into_words=True</span></code> (to lift the ambiguity with a batch of sequences).</p></li>
<li><p><strong>add_special_tokens</strong> (<code class="docutils literal notranslate"><span class="pre">bool</span></code>, <em>optional</em>, defaults to <code class="docutils literal notranslate"><span class="pre">True</span></code>) -- Whether or not to add special tokens when encoding the sequences. This will use the underlying
<a class="reference internal" href="#egrecho.core.tokenizer.Tokenizer.build_inputs_with_special_tokens" title="egrecho.core.tokenizer.Tokenizer.build_inputs_with_special_tokens"><code class="xref py py-meth docutils literal notranslate"><span class="pre">Tokenizer.build_inputs_with_special_tokens()</span></code></a> function, which defines which tokens are
automatically added to the input ids. This is usefull if you want to add <code class="docutils literal notranslate"><span class="pre">bos</span></code> or <code class="docutils literal notranslate"><span class="pre">eos</span></code> tokens
automatically.</p></li>
<li><p><strong>padding</strong> (<code class="docutils literal notranslate"><span class="pre">bool</span></code>, <code class="docutils literal notranslate"><span class="pre">str</span></code> or <a class="reference internal" href="../utils/index.html#egrecho.utils.types.PaddingStrategy" title="egrecho.utils.types.PaddingStrategy"><code class="xref py py-class docutils literal notranslate"><span class="pre">PaddingStrategy</span></code></a>, <em>optional</em>, defaults to <code class="docutils literal notranslate"><span class="pre">False</span></code>) -- Activates and controls padding. Accepts the following values:</p></li>
<li><p><strong>'longest'</strong> (<em>- True or</em>) -- Pad to the longest sequence in the batch (or no padding if only a single
sequence if provided).</p></li>
<li><p><strong>'max_length'</strong> (<em>-</em>) -- Pad to a maximum length specified with the argument <code class="docutils literal notranslate"><span class="pre">max_length</span></code> or to the maximum
acceptable input length for the model if that argument is not provided.</p></li>
<li><p><strong>'do_not_pad'</strong> (<em>- False or</em>) -- No padding (i.e., can output a batch with sequences of different
lengths).</p></li>
<li><p><strong>truncation</strong> (<code class="docutils literal notranslate"><span class="pre">bool</span></code>, <code class="docutils literal notranslate"><span class="pre">str</span></code> or <a class="reference internal" href="#egrecho.core.tokenizer.TruncationStrategy" title="egrecho.core.tokenizer.TruncationStrategy"><code class="xref py py-class docutils literal notranslate"><span class="pre">TruncationStrategy</span></code></a>, <em>optional</em>, defaults to <code class="docutils literal notranslate"><span class="pre">False</span></code>) -- Activates and controls truncation. Accepts the following values:</p></li>
<li><p><strong>'longest_first'</strong> (<em>- True or</em>) -- Truncate to a maximum length specified with the argument <code class="docutils literal notranslate"><span class="pre">max_length</span></code> or</p></li>
<li><p><strong>will</strong> (<em>to the maximum acceptable input length for the model if that argument is not provided. This</em>) -- </p></li>
<li><p><strong>token</strong> (<em>truncate token by</em>) -- </p></li>
<li><p><strong>of</strong> (<em>removing a token from the longest sequence in the pair if a pair</em>) -- </p></li>
<li><p><strong>sequences</strong> (<em>truncate the second sequence</em><em> of </em><em>a pair if a pair of</em>) -- </p></li>
<li><p><strong>'only_first'</strong> (<em>-</em>) -- Truncate to a maximum length specified with the argument <code class="docutils literal notranslate"><span class="pre">max_length</span></code> or to the</p></li>
<li><p><strong>only</strong> (<em>maximum acceptable input length for the model if that argument is not provided. This will</em>) -- </p></li>
<li><p><strong>sequences</strong> -- </p></li>
<li><p><strong>'only_second'</strong> (<em>-</em>) -- Truncate to a maximum length specified with the argument <code class="docutils literal notranslate"><span class="pre">max_length</span></code> or to the</p></li>
<li><p><strong>only</strong> -- </p></li>
<li><p><strong>sequences</strong> -- </p></li>
<li><p><strong>'do_not_truncate'</strong> (<em>- False or</em>) -- No truncation (i.e., can output batch with sequence lengths</p></li>
<li><p><strong>size</strong><strong>)</strong><strong>.</strong> (<em>greater than the model maximum admissible input</em>) -- </p></li>
<li><p><strong>max_length</strong> (<code class="docutils literal notranslate"><span class="pre">int</span></code>, <em>optional</em>) -- <p>Controls the maximum length to use by one of the truncation/padding parameters.</p>
<p>If left unset or set to <code class="docutils literal notranslate"><span class="pre">None</span></code>, this will use the predefined model maximum length if a maximum length
is required by one of the truncation/padding parameters. If the model has no specific maximum input
length (like XLNet) truncation/padding to a maximum length will be deactivated.</p>
</p></li>
<li><p><strong>is_split_into_words</strong> (<code class="docutils literal notranslate"><span class="pre">bool</span></code>, <em>optional</em>, defaults to <code class="docutils literal notranslate"><span class="pre">False</span></code>) -- Whether or not the input is already pre-tokenized (e.g., split into words). If set to <code class="docutils literal notranslate"><span class="pre">True</span></code>, the
tokenizer assumes the input is already split into words (for instance, by splitting it on whitespace)
which it will tokenize. This is useful for NER or token classification.</p></li>
<li><p><strong>**kwargs</strong> -- Additional keyword arguments.</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="egrecho.core.tokenizer.Tokenizer.num_special_tokens_to_add">
<span class="sig-name descname"><span class="pre">num_special_tokens_to_add</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">pair</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span><a class="reference external" href="https://github.com/wangers/subtools2/tree/master/egrecho/core/tokenizer.py#L910-L932"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#egrecho.core.tokenizer.Tokenizer.num_special_tokens_to_add" title="Permalink to this definition">#</a></dt>
<dd><p>Returns the number of added tokens when encoding a sequence with special tokens.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>pair</strong> (<code class="docutils literal notranslate"><span class="pre">bool</span></code>, <em>optional</em>, defaults to <code class="docutils literal notranslate"><span class="pre">False</span></code>) -- Whether the number of added tokens should be computed in the case of a sequence pair or a single
sequence.</p>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>Number of special tokens added to sequences.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><code class="docutils literal notranslate"><span class="pre">int</span></code></p>
</dd>
</dl>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>This encodes a dummy input and checks the number of added tokens, and is therefore not efficient.
Do not put this inside your training loop.</p>
</div>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="egrecho.core.tokenizer.Tokenizer.prepare_for_model">
<span class="sig-name descname"><span class="pre">prepare_for_model</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">ids</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">pair_ids</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">add_special_tokens</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">padding</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">truncation</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">max_length</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">stride</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">pad_to_multiple_of</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">return_tensors</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">return_token_type_ids</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">return_attention_mask</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">return_overflowing_tokens</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">return_special_tokens_mask</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">return_length</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">verbose</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">prepend_batch_axis</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="reference external" href="https://github.com/wangers/subtools2/tree/master/egrecho/core/tokenizer.py#L1002-L1152"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#egrecho.core.tokenizer.Tokenizer.prepare_for_model" title="Permalink to this definition">#</a></dt>
<dd><p>Prepares a sequence of input id, or a pair of sequences of inputs ids so that it can be used by the model. It
adds special tokens, truncates sequences if overflowing while taking into account the special tokens and
manages a moving window (with user defined stride) for overflowing tokens. Please Note, for <em>pair_ids</em>
different than <code class="docutils literal notranslate"><span class="pre">None</span></code> and <em>truncation_strategy = longest_first</em> or <code class="docutils literal notranslate"><span class="pre">True</span></code>, it is not possible to return
overflowing tokens. Such a combination of arguments will raise an error.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>ids</strong> (<code class="docutils literal notranslate"><span class="pre">List[int]</span></code>) -- Tokenized input ids of the first sequence. Can be obtained from a string by the <code class="xref py py-meth docutils literal notranslate"><span class="pre">text2ids()</span></code>.</p></li>
<li><p><strong>pair_ids</strong> (<code class="docutils literal notranslate"><span class="pre">List[int]</span></code>, <em>optional</em>) -- Tokenized input ids of the second sequence. Can be obtained from a string by the <code class="xref py py-meth docutils literal notranslate"><span class="pre">text2ids()</span></code>.</p></li>
<li><p><strong>add_special_tokens</strong> (<code class="docutils literal notranslate"><span class="pre">bool</span></code>, <em>optional</em>, defaults to <code class="docutils literal notranslate"><span class="pre">True</span></code>) -- Whether or not to add special tokens when encoding the sequences. This will use the underlying
<a class="reference internal" href="#egrecho.core.tokenizer.Tokenizer.build_inputs_with_special_tokens" title="egrecho.core.tokenizer.Tokenizer.build_inputs_with_special_tokens"><code class="xref py py-meth docutils literal notranslate"><span class="pre">Tokenizer.build_inputs_with_special_tokens()</span></code></a> function, which defines which tokens are
automatically added to the input ids. This is usefull if you want to add <code class="docutils literal notranslate"><span class="pre">bos</span></code> or <code class="docutils literal notranslate"><span class="pre">eos</span></code> tokens
automatically.</p></li>
<li><p><strong>padding</strong> (<code class="docutils literal notranslate"><span class="pre">bool</span></code>, <code class="docutils literal notranslate"><span class="pre">str</span></code> or :class:<code class="docutils literal notranslate"><span class="pre">~egrecho.utils.types.PaddingStrategy</span></code>, <em>optional</em>, defaults to <code class="docutils literal notranslate"><span class="pre">False</span></code>) -- Activates and controls padding. Accepts the following values:</p></li>
<li><p><strong>'longest'</strong> (<em>- True or</em>) -- Pad to the longest sequence in the batch (or no padding if only a single
sequence if provided).</p></li>
<li><p><strong>'max_length'</strong> (<em>-</em>) -- Pad to a maximum length specified with the argument <code class="docutils literal notranslate"><span class="pre">max_length</span></code> or to the maximum
acceptable input length for the model if that argument is not provided.</p></li>
<li><p><strong>'do_not_pad'</strong> (<em>- False or</em>) -- No padding (i.e., can output a batch with sequences of different
lengths).</p></li>
<li><p><strong>truncation</strong> (<code class="docutils literal notranslate"><span class="pre">bool</span></code>, <code class="docutils literal notranslate"><span class="pre">str</span></code> or :class:<code class="docutils literal notranslate"><span class="pre">~egrecho.core.tokenizer.TruncationStrategy</span></code>, <em>optional</em>, defaults to <code class="docutils literal notranslate"><span class="pre">False</span></code>) -- Activates and controls truncation. Accepts the following values:</p></li>
<li><p><strong>'longest_first'</strong> (<em>- True or</em>) -- Truncate to a maximum length specified with the argument <code class="docutils literal notranslate"><span class="pre">max_length</span></code> or</p></li>
<li><p><strong>will</strong> (<em>to the maximum acceptable input length for the model if that argument is not provided. This</em>) -- </p></li>
<li><p><strong>token</strong> (<em>truncate token by</em>) -- </p></li>
<li><p><strong>of</strong> (<em>removing a token from the longest sequence in the pair if a pair</em>) -- </p></li>
<li><p><strong>sequences</strong> (<em>truncate the second sequence</em><em> of </em><em>a pair if a pair of</em>) -- </p></li>
<li><p><strong>'only_first'</strong> (<em>-</em>) -- Truncate to a maximum length specified with the argument <code class="docutils literal notranslate"><span class="pre">max_length</span></code> or to the</p></li>
<li><p><strong>only</strong> (<em>maximum acceptable input length for the model if that argument is not provided. This will</em>) -- </p></li>
<li><p><strong>sequences</strong> -- </p></li>
<li><p><strong>'only_second'</strong> (<em>-</em>) -- Truncate to a maximum length specified with the argument <code class="docutils literal notranslate"><span class="pre">max_length</span></code> or to the</p></li>
<li><p><strong>only</strong> -- </p></li>
<li><p><strong>sequences</strong> -- </p></li>
<li><p><strong>'do_not_truncate'</strong> (<em>- False or</em>) -- No truncation (i.e., can output batch with sequence lengths</p></li>
<li><p><strong>size</strong><strong>)</strong><strong>.</strong> (<em>greater than the model maximum admissible input</em>) -- </p></li>
<li><p><strong>max_length</strong> (<code class="docutils literal notranslate"><span class="pre">int</span></code>, <em>optional</em>) -- <p>Controls the maximum length to use by one of the truncation/padding parameters.</p>
<p>If left unset or set to <code class="docutils literal notranslate"><span class="pre">None</span></code>, this will use the predefined model maximum length if a maximum length
is required by one of the truncation/padding parameters. If the model has no specific maximum input
length (like XLNet) truncation/padding to a maximum length will be deactivated.</p>
</p></li>
<li><p><strong>stride</strong> (<code class="docutils literal notranslate"><span class="pre">int</span></code>, <em>optional</em>, defaults to 0) -- If set to a number along with <code class="docutils literal notranslate"><span class="pre">max_length</span></code>, the overflowing tokens returned when
<code class="docutils literal notranslate"><span class="pre">return_overflowing_tokens=True</span></code> will contain some tokens from the end of the truncated sequence
returned to provide some overlap between truncated and overflowing sequences. The value of this
argument defines the number of overlapping tokens.</p></li>
<li><p><strong>is_split_into_words</strong> (<code class="docutils literal notranslate"><span class="pre">bool</span></code>, <em>optional</em>, defaults to <code class="docutils literal notranslate"><span class="pre">False</span></code>) -- Whether or not the input is already pre-tokenized (e.g., split into words). If set to <code class="docutils literal notranslate"><span class="pre">True</span></code>, the
tokenizer assumes the input is already split into words (for instance, by splitting it on whitespace)
which it will tokenize. This is useful for NER or token classification.</p></li>
<li><p><strong>pad_to_multiple_of</strong> (<code class="docutils literal notranslate"><span class="pre">int</span></code>, <em>optional</em>) -- If set will pad the sequence to a multiple of the provided value. Requires <code class="docutils literal notranslate"><span class="pre">padding</span></code> to be activated.
This is especially useful to enable the use of Tensor Cores on NVIDIA hardware with compute capability
<code class="docutils literal notranslate"><span class="pre">&gt;=</span> <span class="pre">7.5</span></code> (Volta).</p></li>
<li><p><strong>return_tensors</strong> (<code class="docutils literal notranslate"><span class="pre">str</span></code> or <a class="reference internal" href="#egrecho.core.tokenizer.TensorType" title="egrecho.core.tokenizer.TensorType"><code class="xref py py-class docutils literal notranslate"><span class="pre">TensorType</span></code></a>, <em>optional</em>) -- If set, will return tensors instead of list of python integers. Acceptable values are:</p></li>
<li><p><strong>'pt'</strong> (<em>-</em>) -- Return PyTorch <code class="docutils literal notranslate"><span class="pre">torch.Tensor</span></code> objects.</p></li>
<li><p><strong>'np'</strong> (<em>-</em>) -- Return Numpy <code class="docutils literal notranslate"><span class="pre">np.ndarray</span></code> objects.</p></li>
<li><p><strong>return_token_type_ids</strong> (<code class="docutils literal notranslate"><span class="pre">bool</span></code>, <em>optional</em>) -- Whether to return token type IDs. If left to the default, will return the token type IDs according to
the specific tokenizer’s default, defined by the <code class="docutils literal notranslate"><span class="pre">return_outputs</span></code> attribute.</p></li>
<li><p><strong>return_attention_mask</strong> (<code class="docutils literal notranslate"><span class="pre">bool</span></code>, <em>optional</em>) -- Whether to return the attention mask. If left to the default, will return the attention mask according
to the specific tokenizer’s default, defined by the <code class="docutils literal notranslate"><span class="pre">return_outputs</span></code> attribute.</p></li>
<li><p><strong>return_overflowing_tokens</strong> (<code class="docutils literal notranslate"><span class="pre">bool</span></code>, <em>optional</em>, defaults to <code class="docutils literal notranslate"><span class="pre">False</span></code>) -- Whether or not to return overflowing token sequences. If a pair of sequences of input ids (or a batch
of pairs) is provided with <code class="docutils literal notranslate"><span class="pre">truncation_strategy</span> <span class="pre">=</span> <span class="pre">longest_first</span></code> or <code class="docutils literal notranslate"><span class="pre">True</span></code>, an error is raised instead
of returning overflowing tokens.</p></li>
<li><p><strong>return_special_tokens_mask</strong> (<code class="docutils literal notranslate"><span class="pre">bool</span></code>, <em>optional</em>, defaults to <code class="docutils literal notranslate"><span class="pre">False</span></code>) -- Whether or not to return special tokens mask information.</p></li>
<li><p><strong>return_length</strong> (<code class="docutils literal notranslate"><span class="pre">bool</span></code>, <em>optional</em>, defaults to <code class="docutils literal notranslate"><span class="pre">False</span></code>) -- Whether or not to return the lengths of the encoded inputs.</p></li>
<li><p><strong>verbose</strong> (<code class="docutils literal notranslate"><span class="pre">bool</span></code>, <em>optional</em>, defaults to <code class="docutils literal notranslate"><span class="pre">True</span></code>) -- Whether or not to print more information and warnings.</p></li>
<li><p><strong>**kwargs</strong> -- passed to the <code class="docutils literal notranslate"><span class="pre">self.tokenize()</span></code> method</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p><p>A [<code class="docutils literal notranslate"><span class="pre">BatchEncoding</span></code>] with the following fields:</p>
<ul class="simple">
<li><p><strong>input_ids</strong> -- List of token ids to be fed to a model.</p></li>
<li><p><strong>token_type_ids</strong> -- List of token type ids to be fed to a model (when <code class="docutils literal notranslate"><span class="pre">return_token_type_ids=True</span></code> or
if <em>“token_type_ids”</em> is in <code class="docutils literal notranslate"><span class="pre">self.model_input_names</span></code>).</p></li>
<li><p><strong>attention_mask</strong> -- List of indices specifying which tokens should be attended to by the model (when
<code class="docutils literal notranslate"><span class="pre">return_attention_mask=True</span></code> or if <em>“attention_mask”</em> is in <code class="docutils literal notranslate"><span class="pre">self.model_input_names</span></code>).</p></li>
<li><p><strong>overflowing_tokens</strong> -- List of overflowing tokens sequences (when a <code class="docutils literal notranslate"><span class="pre">max_length</span></code> is specified and
<code class="docutils literal notranslate"><span class="pre">return_overflowing_tokens=True</span></code>).</p></li>
<li><p><strong>num_truncated_tokens</strong> -- Number of tokens truncated (when a <code class="docutils literal notranslate"><span class="pre">max_length</span></code> is specified and
<code class="docutils literal notranslate"><span class="pre">return_overflowing_tokens=True</span></code>).</p></li>
<li><p><strong>special_tokens_mask</strong> -- List of 0s and 1s, with 1 specifying added special tokens and 0 specifying
regular sequence tokens (when <code class="docutils literal notranslate"><span class="pre">add_special_tokens=True</span></code> and <code class="docutils literal notranslate"><span class="pre">return_special_tokens_mask=True</span></code>).</p></li>
<li><p><strong>length</strong> -- The length of the inputs (when <code class="docutils literal notranslate"><span class="pre">return_length=True</span></code>)</p></li>
</ul>
</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>[<code class="docutils literal notranslate"><span class="pre">BatchEncoding</span></code>]</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="egrecho.core.tokenizer.Tokenizer.truncate_sequences">
<span class="sig-name descname"><span class="pre">truncate_sequences</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">ids</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">pair_ids</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">num_tokens_to_remove</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">truncation_strategy</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'longest_first'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">stride</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0</span></span></em><span class="sig-paren">)</span><a class="reference external" href="https://github.com/wangers/subtools2/tree/master/egrecho/core/tokenizer.py#L1154-L1286"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#egrecho.core.tokenizer.Tokenizer.truncate_sequences" title="Permalink to this definition">#</a></dt>
<dd><p>Truncates a sequence pair in-place following the strategy.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>ids</strong> (<code class="docutils literal notranslate"><span class="pre">List[int]</span></code>) -- Tokenized input ids of the first sequence. Can be obtained from a string by the :meth:<code class="docutils literal notranslate"><span class="pre">text2ids</span></code>.</p></li>
<li><p><strong>pair_ids</strong> (<code class="docutils literal notranslate"><span class="pre">List[int]</span></code>, <em>optional</em>) -- Tokenized input ids of the second sequence. Can be obtained from a string by the :meth:<code class="docutils literal notranslate"><span class="pre">text2ids</span></code>.</p></li>
<li><p><strong>num_tokens_to_remove</strong> (<code class="docutils literal notranslate"><span class="pre">int</span></code>, <em>optional</em>, defaults to 0) -- Number of tokens to remove using the truncation strategy.</p></li>
<li><p><strong>truncation_strategy</strong> (<code class="docutils literal notranslate"><span class="pre">str</span></code> or <a class="reference internal" href="#egrecho.core.tokenizer.TruncationStrategy" title="egrecho.core.tokenizer.TruncationStrategy"><code class="xref py py-class docutils literal notranslate"><span class="pre">TruncationStrategy</span></code></a>, <em>optional</em>, defaults to <code class="docutils literal notranslate"><span class="pre">False</span></code>) -- The strategy to follow for truncation. Can be:</p></li>
<li><p><strong>'longest_first'</strong> (<em>-</em>) -- Truncate to a maximum length specified with the argument <code class="docutils literal notranslate"><span class="pre">max_length</span></code> or to the
maximum acceptable input length for the model if that argument is not provided. This will truncate
token by token, removing a token from the longest sequence in the pair if a pair of sequences (or a
batch of pairs) is provided.</p></li>
<li><p><strong>'only_first'</strong> (<em>-</em>) -- Truncate to a maximum length specified with the argument <code class="docutils literal notranslate"><span class="pre">max_length</span></code> or to the
maximum acceptable input length for the model if that argument is not provided. This will only
truncate the first sequence of a pair if a pair of sequences (or a batch of pairs) is provided.</p></li>
<li><p><strong>'only_second'</strong> (<em>-</em>) -- Truncate to a maximum length specified with the argument <code class="docutils literal notranslate"><span class="pre">max_length</span></code> or to the
maximum acceptable input length for the model if that argument is not provided. This will only
truncate the second sequence of a pair if a pair of sequences (or a batch of pairs) is provided.</p></li>
<li><p><strong>'do_not_truncate'</strong> (<em>-</em>) -- No truncation (i.e., can output batch with sequence lengths greater
than the model maximum admissible input size).</p></li>
<li><p><strong>stride</strong> (<code class="docutils literal notranslate"><span class="pre">int</span></code>, <em>optional</em>, defaults to 0) -- If set to a positive number, the overflowing tokens returned will contain some tokens from the main
sequence returned. The value of this argument defines the number of additional tokens.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>The truncated <code class="docutils literal notranslate"><span class="pre">ids</span></code>, the truncated <code class="docutils literal notranslate"><span class="pre">pair_ids</span></code> and the list of
overflowing tokens. Note: The <em>longest_first</em> strategy returns empty list of overflowing tokens if a pair
of sequences (or a batch of pairs) is provided.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><code class="docutils literal notranslate"><span class="pre">Tuple[List[int],</span> <span class="pre">List[int],</span> <span class="pre">List[int]]</span></code></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="egrecho.core.tokenizer.Tokenizer.build_inputs_with_special_tokens">
<span class="sig-name descname"><span class="pre">build_inputs_with_special_tokens</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">token_ids_0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">token_ids_1</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference external" href="https://github.com/wangers/subtools2/tree/master/egrecho/core/tokenizer.py#L1288-L1306"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#egrecho.core.tokenizer.Tokenizer.build_inputs_with_special_tokens" title="Permalink to this definition">#</a></dt>
<dd><p>Build model inputs from a sequence or a pair of sequence for sequence classification tasks by concatenating and
adding special tokens.</p>
<p>This implementation does not add special tokens and this method should be overridden in a subclass.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>token_ids_0</strong> (<code class="docutils literal notranslate"><span class="pre">List[int]</span></code>) -- The first tokenized sequence.</p></li>
<li><p><strong>token_ids_1</strong> (<code class="docutils literal notranslate"><span class="pre">List[int]</span></code>, <em>optional</em>) -- The second tokenized sequence.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>The model input with special tokens.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><code class="docutils literal notranslate"><span class="pre">List[int]</span></code></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="egrecho.core.tokenizer.Tokenizer.create_token_type_ids_from_sequences">
<span class="sig-name descname"><span class="pre">create_token_type_ids_from_sequences</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">token_ids_0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">token_ids_1</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference external" href="https://github.com/wangers/subtools2/tree/master/egrecho/core/tokenizer.py#L1308-L1324"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#egrecho.core.tokenizer.Tokenizer.create_token_type_ids_from_sequences" title="Permalink to this definition">#</a></dt>
<dd><p>Create the token type IDs corresponding to the sequences passed.
Should be overridden in a subclass if the model has a special way of building those.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>token_ids_0</strong> (<code class="docutils literal notranslate"><span class="pre">List[int]</span></code>) -- The first tokenized sequence.</p></li>
<li><p><strong>token_ids_1</strong> (<code class="docutils literal notranslate"><span class="pre">List[int]</span></code>, <em>optional</em>) -- The second tokenized sequence.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>The token type ids.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><code class="docutils literal notranslate"><span class="pre">List[int]</span></code></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="egrecho.core.tokenizer.Tokenizer.get_special_tokens_mask">
<span class="sig-name descname"><span class="pre">get_special_tokens_mask</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">token_ids_0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">token_ids_1</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">already_has_special_tokens</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span><a class="reference external" href="https://github.com/wangers/subtools2/tree/master/egrecho/core/tokenizer.py#L1326-L1360"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#egrecho.core.tokenizer.Tokenizer.get_special_tokens_mask" title="Permalink to this definition">#</a></dt>
<dd><p>Retrieves sequence ids from a token list that has no special tokens added. This method is called when adding
special tokens using the tokenizer <cite>prepare_for_model</cite>.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>token_ids_0</strong> (<code class="docutils literal notranslate"><span class="pre">List[int]</span></code>) -- List of ids of the first sequence.</p></li>
<li><p><strong>token_ids_1</strong> (<code class="docutils literal notranslate"><span class="pre">List[int]</span></code>, <em>optional</em>) -- List of ids of the second sequence.</p></li>
<li><p><strong>already_has_special_tokens</strong> (<code class="docutils literal notranslate"><span class="pre">bool</span></code>, <em>optional</em>, defaults to <code class="docutils literal notranslate"><span class="pre">False</span></code>) -- Whether or not the token list is already formatted with special tokens for the model.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>1 for a special token, 0 for a sequence token.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>A list of integers in the range [0, 1]</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="egrecho.core.tokenizer.Tokenizer.pad">
<span class="sig-name descname"><span class="pre">pad</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">encoded_inputs</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">padding</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">max_length</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">pad_to_multiple_of</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">return_attention_mask</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">return_tensors</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">verbose</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em><span class="sig-paren">)</span><a class="reference external" href="https://github.com/wangers/subtools2/tree/master/egrecho/core/tokenizer.py#L1362-L1528"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#egrecho.core.tokenizer.Tokenizer.pad" title="Permalink to this definition">#</a></dt>
<dd><p>Pad a single encoded input or a batch of encoded inputs up to predefined length or to the max sequence length
in the batch.</p>
<p>Padding side (left/right) padding token ids are defined at the tokenizer level (with <code class="docutils literal notranslate"><span class="pre">self.padding_side</span></code>,
<code class="docutils literal notranslate"><span class="pre">self.pad_token_id</span></code> and <code class="docutils literal notranslate"><span class="pre">self.pad_token_type_id</span></code>).</p>
<p>Please note that with a fast tokenizer, using the <code class="docutils literal notranslate"><span class="pre">__call__</span></code> method is faster than using a method to encode the
text followed by a call to the <code class="docutils literal notranslate"><span class="pre">pad</span></code> method to get a padded encoding.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>If the <code class="docutils literal notranslate"><span class="pre">encoded_inputs</span></code> passed are dictionary of numpy arrays or PyTorch tensors, the
result will use the same type unless you provide a different tensor type with <code class="docutils literal notranslate"><span class="pre">return_tensors</span></code>. In the case of
PyTorch tensors, you will lose the specific device of your tensors however.</p>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>encoded_inputs</strong> ([<code class="docutils literal notranslate"><span class="pre">BatchEncoding</span></code>], list of [<code class="docutils literal notranslate"><span class="pre">BatchEncoding</span></code>], <code class="docutils literal notranslate"><span class="pre">Dict[str,</span> <span class="pre">List[int]]</span></code>, <code class="docutils literal notranslate"><span class="pre">Dict[str,</span> <span class="pre">List[List[int]]</span></code> or <code class="docutils literal notranslate"><span class="pre">List[Dict[str,</span> <span class="pre">List[int]]]</span></code>) -- <p>Tokenized inputs. Can represent one input ([<code class="docutils literal notranslate"><span class="pre">BatchEncoding</span></code>] or <code class="docutils literal notranslate"><span class="pre">Dict[str,</span> <span class="pre">List[int]]</span></code>) or a batch of
tokenized inputs (list of [<code class="docutils literal notranslate"><span class="pre">BatchEncoding</span></code>], <em>Dict[str, List[List[int]]]</em> or <em>List[Dict[str,
List[int]]]</em>) so you can use this method during preprocessing as well as in a PyTorch Dataloader
collate function.</p>
<p>Instead of <code class="docutils literal notranslate"><span class="pre">List[int]</span></code> you can have tensors (numpy arrays, PyTorch tensors), see
the note above for the return type.</p>
</p></li>
<li><p><strong>padding</strong> (<code class="docutils literal notranslate"><span class="pre">bool</span></code>, <code class="docutils literal notranslate"><span class="pre">str</span></code> or <a class="reference internal" href="../utils/index.html#egrecho.utils.types.PaddingStrategy" title="egrecho.utils.types.PaddingStrategy"><code class="xref py py-class docutils literal notranslate"><span class="pre">PaddingStrategy</span></code></a>, <em>optional</em>, defaults to <code class="docutils literal notranslate"><span class="pre">True</span></code>) -- Select a strategy to pad the returned sequences (according to the model’s padding side and padding
index) among:</p></li>
<li><p><strong>'longest'</strong> (<em>- True or</em>) -- Pad to the longest sequence in the batch (or no padding if only a single
sequence if provided).</p></li>
<li><p><strong>'max_length'</strong> (<em>-</em>) -- Pad to a maximum length specified with the argument <code class="docutils literal notranslate"><span class="pre">max_length</span></code> or to the maximum
acceptable input length for the model if that argument is not provided.</p></li>
<li><p><strong>'do_not_pad'</strong> (<em>- False or</em>) -- No padding (i.e., can output a batch with sequences of different
lengths).</p></li>
<li><p><strong>max_length</strong> (<code class="docutils literal notranslate"><span class="pre">int</span></code>, <em>optional</em>) -- Maximum length of the returned list and optionally padding length (see above).</p></li>
<li><p><strong>pad_to_multiple_of</strong> (<code class="docutils literal notranslate"><span class="pre">int</span></code>, <em>optional</em>) -- <p>If set will pad the sequence to a multiple of the provided value.</p>
<p>This is especially useful to enable the use of Tensor Cores on NVIDIA hardware with compute capability
<code class="docutils literal notranslate"><span class="pre">&gt;=</span> <span class="pre">7.5</span></code> (Volta).</p>
</p></li>
<li><p><strong>return_attention_mask</strong> (<code class="docutils literal notranslate"><span class="pre">bool</span></code>, <em>optional</em>) -- Whether to return the attention mask. If left to the default, will return the attention mask according
to the specific tokenizer’s default, defined by the <code class="docutils literal notranslate"><span class="pre">return_outputs</span></code> attribute.</p></li>
<li><p><strong>return_tensors</strong> (<code class="docutils literal notranslate"><span class="pre">str</span></code> or <a class="reference internal" href="#egrecho.core.tokenizer.TensorType" title="egrecho.core.tokenizer.TensorType"><code class="xref py py-class docutils literal notranslate"><span class="pre">TensorType</span></code></a>, <em>optional</em>) -- If set, will return tensors instead of list of python integers. Acceptable values are:</p></li>
<li><p><strong>'pt'</strong> (<em>-</em>) -- Return PyTorch <code class="docutils literal notranslate"><span class="pre">torch.Tensor</span></code> objects.</p></li>
<li><p><strong>'np'</strong> (<em>-</em>) -- Return Numpy <code class="docutils literal notranslate"><span class="pre">np.ndarray</span></code> objects.</p></li>
<li><p><strong>verbose</strong> (<code class="docutils literal notranslate"><span class="pre">bool</span></code>, <em>optional</em>, defaults to <code class="docutils literal notranslate"><span class="pre">True</span></code>) -- Whether or not to print more information and warnings.</p></li>
</ul>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p><span class="sphinx_autodoc_typehints-type"><code class="xref py py-class docutils literal notranslate"><span class="pre">UserDict</span></code></span></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="egrecho.core.tokenizer.Tokenizer.batch_decode">
<span class="sig-name descname"><span class="pre">batch_decode</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">sequences</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">skip_special_tokens</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="reference external" href="https://github.com/wangers/subtools2/tree/master/egrecho/core/tokenizer.py#L1650-L1677"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#egrecho.core.tokenizer.Tokenizer.batch_decode" title="Permalink to this definition">#</a></dt>
<dd><p>Convert a list of lists of token ids into a list of strings by calling decode.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>sequences</strong> (<code class="docutils literal notranslate"><span class="pre">Union[List[int],</span> <span class="pre">List[List[int]],</span> <span class="pre">np.ndarray,</span> <span class="pre">torch.Tensor]</span></code>) -- List of tokenized input ids. Can be obtained using the <a class="reference internal" href="#egrecho.core.tokenizer.Tokenizer.__call__" title="egrecho.core.tokenizer.Tokenizer.__call__"><code class="xref py py-meth docutils literal notranslate"><span class="pre">__call__()</span></code></a> method.</p></li>
<li><p><strong>skip_special_tokens</strong> (<code class="docutils literal notranslate"><span class="pre">bool</span></code>, <em>optional</em>, defaults to <code class="docutils literal notranslate"><span class="pre">False</span></code>) -- Whether or not to remove special tokens in the decoding.</p></li>
<li><p><strong>**kwargs</strong> (additional keyword arguments, <em>optional</em>) -- Will be passed to the underlying model specific decode method.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>The list of decoded sentences.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><code class="docutils literal notranslate"><span class="pre">List[str]</span></code></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="egrecho.core.tokenizer.Tokenizer.decode">
<span class="sig-name descname"><span class="pre">decode</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">token_ids</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">skip_special_tokens</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="reference external" href="https://github.com/wangers/subtools2/tree/master/egrecho/core/tokenizer.py#L1679-L1709"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#egrecho.core.tokenizer.Tokenizer.decode" title="Permalink to this definition">#</a></dt>
<dd><p>Converts a sequence of ids in a string, using the tokenizer and vocabulary with options to remove special
tokens and clean up tokenization spaces.</p>
<p>Similar to doing <code class="docutils literal notranslate"><span class="pre">self.ids2text(token_ids)</span></code>.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>token_ids</strong> (<code class="docutils literal notranslate"><span class="pre">Union[int,</span> <span class="pre">List[int],</span> <span class="pre">np.ndarray,</span> <span class="pre">torch.Tensor]</span></code>) -- List of tokenized input ids. Can be obtained using the <a class="reference internal" href="#egrecho.core.tokenizer.Tokenizer.__call__" title="egrecho.core.tokenizer.Tokenizer.__call__"><code class="xref py py-meth docutils literal notranslate"><span class="pre">__call__()</span></code></a> method.</p></li>
<li><p><strong>skip_special_tokens</strong> (<code class="docutils literal notranslate"><span class="pre">bool</span></code>, <em>optional</em>, defaults to <code class="docutils literal notranslate"><span class="pre">False</span></code>) -- Whether or not to remove special tokens in the decoding.</p></li>
<li><p><strong>**kwargs</strong> (additional keyword arguments, <em>optional</em>) -- Will be passed to the underlying model specific decode method.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>The decoded sentence.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><code class="docutils literal notranslate"><span class="pre">str</span></code></p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="egrecho.core.tokenizer.convert_to_tensors">
<span class="sig-prename descclassname"><span class="pre">egrecho.core.tokenizer.</span></span><span class="sig-name descname"><span class="pre">convert_to_tensors</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">encoded_inputs</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">tensor_type</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">prepend_batch_axis</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span><a class="reference external" href="https://github.com/wangers/subtools2/tree/master/egrecho/core/tokenizer.py#L1736-L1818"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#egrecho.core.tokenizer.convert_to_tensors" title="Permalink to this definition">#</a></dt>
<dd><p>Convert the inner content of a dict to tensors.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>encoded_inputs</strong> (<em>Union</em><em>[</em><em>Dict</em><em>[</em><em>str</em><em>, </em><em>EncodedInput</em><em>]</em><em>, </em><em>UserDict</em><em>]</em>) -- encoded inputs.</p></li>
<li><p><strong>tensor_type</strong> (<code class="docutils literal notranslate"><span class="pre">str</span></code> or <a class="reference internal" href="#egrecho.core.tokenizer.TensorType" title="egrecho.core.tokenizer.TensorType"><code class="xref py py-class docutils literal notranslate"><span class="pre">TensorType</span></code></a>, <em>optional</em>) -- The type of tensors to use. If <code class="docutils literal notranslate"><span class="pre">str</span></code>, should be one of the values of the enum <a class="reference internal" href="#egrecho.core.tokenizer.TensorType" title="egrecho.core.tokenizer.TensorType"><code class="xref py py-class docutils literal notranslate"><span class="pre">TensorType</span></code></a>. If
<code class="docutils literal notranslate"><span class="pre">None</span></code>, no modification is done.</p></li>
<li><p><strong>prepend_batch_axis</strong> (<code class="docutils literal notranslate"><span class="pre">int</span></code>, <em>optional</em>, defaults to <code class="docutils literal notranslate"><span class="pre">False</span></code>) -- Whether or not to add the batch dimension during the conversion.</p></li>
</ul>
</dd>
</dl>
</dd></dl>

</section>

        </article>
      </div>
      <footer>
        
        <div class="related-pages">
          <a class="next-page" href="../utils/index.html">
              <div class="page-info">
                <div class="context">
                  <span>Next</span>
                </div>
                <div class="title">egrecho.utils.apply</div>
              </div>
              <svg class="furo-related-icon"><use href="#svg-arrow-right"></use></svg>
            </a>
          <a class="prev-page" href="teacher.html">
              <svg class="furo-related-icon"><use href="#svg-arrow-right"></use></svg>
              <div class="page-info">
                <div class="context">
                  <span>Previous</span>
                </div>
                
                <div class="title">egrecho.core.teacher</div>
                
              </div>
            </a>
        </div>
        <div class="bottom-of-page">
          <div class="left-details">
            <div class="copyright">
                Copyright &#169; 2024, Dexin Liao
            </div>
            Made with <a href="https://www.sphinx-doc.org/">Sphinx</a> and <a class="muted-link" href="https://pradyunsg.me">@pradyunsg</a>'s
            
            <a href="https://github.com/pradyunsg/furo">Furo</a>
            
          </div>
          <div class="right-details">
            
          </div>
        </div>
        
      </footer>
    </div>
    <aside class="toc-drawer">
      
      
      <div class="toc-sticky toc-scroll">
        <div class="toc-title-container">
          <span class="toc-title">
            On this page
          </span>
        </div>
        <div class="toc-tree-container">
          <div class="toc-tree">
            <ul>
<li><a class="reference internal" href="#">egrecho.core.tokenizer</a><ul>
<li><a class="reference internal" href="#egrecho.core.tokenizer.TruncationStrategy"><code class="docutils literal notranslate"><span class="pre">TruncationStrategy</span></code></a></li>
<li><a class="reference internal" href="#egrecho.core.tokenizer.TensorType"><code class="docutils literal notranslate"><span class="pre">TensorType</span></code></a></li>
<li><a class="reference internal" href="#egrecho.core.tokenizer.BaseTokenizerConfig"><code class="docutils literal notranslate"><span class="pre">BaseTokenizerConfig</span></code></a><ul>
<li><a class="reference internal" href="#egrecho.core.tokenizer.BaseTokenizerConfig.extra_files_names"><code class="docutils literal notranslate"><span class="pre">BaseTokenizerConfig.extra_files_names</span></code></a></li>
<li><a class="reference internal" href="#egrecho.core.tokenizer.BaseTokenizerConfig.get_extra_files"><code class="docutils literal notranslate"><span class="pre">BaseTokenizerConfig.get_extra_files()</span></code></a></li>
<li><a class="reference internal" href="#egrecho.core.tokenizer.BaseTokenizerConfig.from_cfg_dir"><code class="docutils literal notranslate"><span class="pre">BaseTokenizerConfig.from_cfg_dir()</span></code></a></li>
<li><a class="reference internal" href="#egrecho.core.tokenizer.BaseTokenizerConfig.copy_extras"><code class="docutils literal notranslate"><span class="pre">BaseTokenizerConfig.copy_extras()</span></code></a></li>
</ul>
</li>
<li><a class="reference internal" href="#egrecho.core.tokenizer.BaseTokenizer"><code class="docutils literal notranslate"><span class="pre">BaseTokenizer</span></code></a><ul>
<li><a class="reference internal" href="#egrecho.core.tokenizer.BaseTokenizer.cls"><code class="docutils literal notranslate"><span class="pre">BaseTokenizer.cls</span></code></a></li>
<li><a class="reference internal" href="#egrecho.core.tokenizer.BaseTokenizer.sep"><code class="docutils literal notranslate"><span class="pre">BaseTokenizer.sep</span></code></a></li>
<li><a class="reference internal" href="#egrecho.core.tokenizer.BaseTokenizer.pad"><code class="docutils literal notranslate"><span class="pre">BaseTokenizer.pad</span></code></a></li>
<li><a class="reference internal" href="#egrecho.core.tokenizer.BaseTokenizer.pad_token_id"><code class="docutils literal notranslate"><span class="pre">BaseTokenizer.pad_token_id</span></code></a></li>
<li><a class="reference internal" href="#egrecho.core.tokenizer.BaseTokenizer.pad_token_type_id"><code class="docutils literal notranslate"><span class="pre">BaseTokenizer.pad_token_type_id</span></code></a></li>
<li><a class="reference internal" href="#egrecho.core.tokenizer.BaseTokenizer.eod"><code class="docutils literal notranslate"><span class="pre">BaseTokenizer.eod</span></code></a></li>
<li><a class="reference internal" href="#egrecho.core.tokenizer.BaseTokenizer.bos"><code class="docutils literal notranslate"><span class="pre">BaseTokenizer.bos</span></code></a></li>
<li><a class="reference internal" href="#egrecho.core.tokenizer.BaseTokenizer.eos"><code class="docutils literal notranslate"><span class="pre">BaseTokenizer.eos</span></code></a></li>
<li><a class="reference internal" href="#egrecho.core.tokenizer.BaseTokenizer.mask"><code class="docutils literal notranslate"><span class="pre">BaseTokenizer.mask</span></code></a></li>
<li><a class="reference internal" href="#egrecho.core.tokenizer.BaseTokenizer.all_special_ids"><code class="docutils literal notranslate"><span class="pre">BaseTokenizer.all_special_ids</span></code></a></li>
<li><a class="reference internal" href="#egrecho.core.tokenizer.BaseTokenizer.vocab_size"><code class="docutils literal notranslate"><span class="pre">BaseTokenizer.vocab_size</span></code></a></li>
<li><a class="reference internal" href="#egrecho.core.tokenizer.BaseTokenizer.config"><code class="docutils literal notranslate"><span class="pre">BaseTokenizer.config</span></code></a></li>
<li><a class="reference internal" href="#egrecho.core.tokenizer.BaseTokenizer.extradir"><code class="docutils literal notranslate"><span class="pre">BaseTokenizer.extradir</span></code></a></li>
<li><a class="reference internal" href="#egrecho.core.tokenizer.BaseTokenizer.from_cfg_dir"><code class="docutils literal notranslate"><span class="pre">BaseTokenizer.from_cfg_dir()</span></code></a></li>
<li><a class="reference internal" href="#egrecho.core.tokenizer.BaseTokenizer.save_to"><code class="docutils literal notranslate"><span class="pre">BaseTokenizer.save_to()</span></code></a></li>
<li><a class="reference internal" href="#egrecho.core.tokenizer.BaseTokenizer.save_config"><code class="docutils literal notranslate"><span class="pre">BaseTokenizer.save_config()</span></code></a></li>
<li><a class="reference internal" href="#egrecho.core.tokenizer.BaseTokenizer.save_extras"><code class="docutils literal notranslate"><span class="pre">BaseTokenizer.save_extras()</span></code></a></li>
<li><a class="reference internal" href="#egrecho.core.tokenizer.BaseTokenizer.default_save_extras"><code class="docutils literal notranslate"><span class="pre">BaseTokenizer.default_save_extras()</span></code></a></li>
</ul>
</li>
<li><a class="reference internal" href="#egrecho.core.tokenizer.Tokenizer"><code class="docutils literal notranslate"><span class="pre">Tokenizer</span></code></a><ul>
<li><a class="reference internal" href="#egrecho.core.tokenizer.Tokenizer.input_text_batched"><code class="docutils literal notranslate"><span class="pre">Tokenizer.input_text_batched()</span></code></a></li>
<li><a class="reference internal" href="#egrecho.core.tokenizer.Tokenizer.__call__"><code class="docutils literal notranslate"><span class="pre">Tokenizer.__call__()</span></code></a></li>
<li><a class="reference internal" href="#egrecho.core.tokenizer.Tokenizer.num_special_tokens_to_add"><code class="docutils literal notranslate"><span class="pre">Tokenizer.num_special_tokens_to_add()</span></code></a></li>
<li><a class="reference internal" href="#egrecho.core.tokenizer.Tokenizer.prepare_for_model"><code class="docutils literal notranslate"><span class="pre">Tokenizer.prepare_for_model()</span></code></a></li>
<li><a class="reference internal" href="#egrecho.core.tokenizer.Tokenizer.truncate_sequences"><code class="docutils literal notranslate"><span class="pre">Tokenizer.truncate_sequences()</span></code></a></li>
<li><a class="reference internal" href="#egrecho.core.tokenizer.Tokenizer.build_inputs_with_special_tokens"><code class="docutils literal notranslate"><span class="pre">Tokenizer.build_inputs_with_special_tokens()</span></code></a></li>
<li><a class="reference internal" href="#egrecho.core.tokenizer.Tokenizer.create_token_type_ids_from_sequences"><code class="docutils literal notranslate"><span class="pre">Tokenizer.create_token_type_ids_from_sequences()</span></code></a></li>
<li><a class="reference internal" href="#egrecho.core.tokenizer.Tokenizer.get_special_tokens_mask"><code class="docutils literal notranslate"><span class="pre">Tokenizer.get_special_tokens_mask()</span></code></a></li>
<li><a class="reference internal" href="#egrecho.core.tokenizer.Tokenizer.pad"><code class="docutils literal notranslate"><span class="pre">Tokenizer.pad()</span></code></a></li>
<li><a class="reference internal" href="#egrecho.core.tokenizer.Tokenizer.batch_decode"><code class="docutils literal notranslate"><span class="pre">Tokenizer.batch_decode()</span></code></a></li>
<li><a class="reference internal" href="#egrecho.core.tokenizer.Tokenizer.decode"><code class="docutils literal notranslate"><span class="pre">Tokenizer.decode()</span></code></a></li>
</ul>
</li>
<li><a class="reference internal" href="#egrecho.core.tokenizer.convert_to_tensors"><code class="docutils literal notranslate"><span class="pre">convert_to_tensors()</span></code></a></li>
</ul>
</li>
</ul>

          </div>
        </div>
      </div>
      
      
    </aside>
  </div>
</div><script data-url_root="../../" id="documentation_options" src="../../_static/documentation_options.js?v=b3ba4146"></script>
    <script src="../../_static/doctools.js?v=888ff710"></script>
    <script src="../../_static/sphinx_highlight.js?v=4825356b"></script>
    <script src="../../_static/scripts/furo.js?v=4e2eecee"></script>
    <script src="../../_static/clipboard.min.js?v=a7894cd8"></script>
    <script src="../../_static/copybutton.js?v=4ea706d9"></script>
    <script src="../../_static/tabs.js?v=3ee01567"></script>
    <script>let toggleHintShow = 'Click to show';</script>
    <script>let toggleHintHide = 'Click to hide';</script>
    <script>let toggleOpenOnPrint = 'true';</script>
    <script src="../../_static/togglebutton.js?v=4a39c7ea"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
    </body>
</html>